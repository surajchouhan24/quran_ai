# dynamic_recitation_corrected.py
import sounddevice as sd
import numpy as np
import whisper
from rapidfuzz import fuzz
import queue
import threading

# -------------------------------
# Configuration
# -------------------------------
MODEL_NAME = "medium"  # whisper model
SAMPLERATE = 16000
BLOCKSIZE = 16000  # 1 sec chunk
MATCH_THRESHOLD = 70  # fuzzy matching threshold (0-100)

# Split reference into lines
REFERENCE_TEXT = """
рд╢реНрд░реА рд╣рдиреБрдорд╛рди рдЪрд╛рд▓реАрд╕рд╛ рдХрд┐рдХ рдкрдВ рджреЛрд╣рд╛ рд╢реНрд░реАрдЧреБрд░реБ рдЪрд░рди рд╕рд░реЛрдЬ рд░рдЬ рдирд┐рдЬ рдордиреБ рдореБрдХреБрд░реБ рд╕реБрдзрд╛рд░рд┐ред
рдмрд░рдирдКрдБ рд░рдШреБрдмрд░ рдмрд┐рдорд▓ рдЬрд╕реБ рдЬреЛ рджрд╛рдпрдХреБ рдлрд▓ рдЪрд╛рд░рд┐ рдмреБрджреНрдзрд┐рд╣реАрди рддрдиреБ рдЬрд╛рдирд┐рдХреЗ рд╕реБрдорд┐рд░реЛрдВ рдкрд╡рдирдХреБрдорд╛рд░ред
рдмрд▓ рдмреБрджреНрдзрд┐ рдмрд┐рджреНрдпрд╛ рджреЗрд╣реБ рдореЛрд╣рд┐рдВ рд╣рд░рд╣реБ рдХрд▓реЗрд╕ рдмрд┐рдХрд╛рд░ рдЬрдп рд╣рдиреБрдорд╛рди рдЬреНрдЮрд╛рди рдЧреБрди рд╕рд╛рдЧрд░ред
рдЬрдп рдХрдкреАрд╕ рддрд┐рд╣реБрдБ рд▓реЛрдХ рдЙрдЬрд╛рдЧрд░ рд░рд╛рдо рджреВрдд рдЕрддреБрд▓рд┐рдд рдмрд▓ рдзрд╛рдорд╛ред
рдЕрдВрдЬрдирд┐рдкреБрддреНрд░ рдкрд╡рдирд╕реБрдд рдирд╛рдорд╛ рдорд╣рд╛рдмреАрд░ рдмрд┐рдХреНрд░рдо рдмрдЬрд░рдВрдЧреАред
""".strip().split("\n")

# -------------------------------
# Globals
# -------------------------------
audio_queue = queue.Queue()
stop_flag = threading.Event()
current_line_index = 0
model = whisper.load_model(MODEL_NAME)

# -------------------------------
# Audio callback
# -------------------------------
def callback(indata, frames, time, status):
    if status:
        print(status)
    audio_queue.put(indata.copy())

# -------------------------------
# Match line
# -------------------------------
def match_line(recognized_text, line_text):
    recognized_text = recognized_text.replace("\n", " ").strip()
    line_text = line_text.replace("\n", " ").strip()
    score = fuzz.partial_ratio(recognized_text, line_text)
    return score

# -------------------------------
# Audio processing thread
# -------------------------------
def process_audio():
    global current_line_index
    buffer = np.zeros((0, 1), dtype=np.float32)
    while not stop_flag.is_set():
        try:
            chunk = audio_queue.get(timeout=1)
        except queue.Empty:
            continue
        buffer = np.concatenate((buffer, chunk), axis=0)

        # Process every 3 seconds
        if len(buffer) >= SAMPLERATE * 3:
            audio_input = buffer.flatten()
            buffer = np.zeros((0, 1), dtype=np.float32)
            
            # Whisper expects float32 [-1,1]
            result = model.transcribe(audio_input, fp16=False, language="hi")
            recognized_text = result["text"].strip()
            
            if current_line_index >= len(REFERENCE_TEXT):
                print("ЁЯОЙ Recitation complete!")
                stop_flag.set()
                break

            line_text = REFERENCE_TEXT[current_line_index]
            score = match_line(recognized_text, line_text)

            if score >= MATCH_THRESHOLD:
                print(f"тЬЕ MATCH [{score}%] Line {current_line_index+1}: {line_text}")
                current_line_index += 1
            else:
                print(f"тЭМ MISMATCH [{score}%] Line {current_line_index+1}: {recognized_text}")

# -------------------------------
# Main
# -------------------------------
def main():
    print("ЁЯОд Start recitation. Press Ctrl+C to stop...")
    threading.Thread(target=process_audio, daemon=True).start()
    try:
        with sd.InputStream(channels=1, samplerate=SAMPLERATE,
                            blocksize=BLOCKSIZE, callback=callback):
            while not stop_flag.is_set():
                sd.sleep(500)
    except KeyboardInterrupt:
        stop_flag.set()
        print("\nЁЯЫС Stopped.")

if __name__ == "__main__":
    main()
